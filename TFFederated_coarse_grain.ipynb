{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Tesi_TFFederated.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa7scGhNTL4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a72a3e8b-4c19-45c2-a710-02e75723f9ea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lf7Qm4Tw0hU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06eb00a7-252c-41f1-ae93-d0cf00c79cef"
      },
      "source": [
        "#@test {\"skip\": true}\n",
        "!pip install --quiet --upgrade tensorflow_federated\n",
        "!pip install nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▋                               | 10kB 22.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 29.5MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 24.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 22.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 51kB 23.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 61kB 16.4MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 17.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 81kB 17.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 92kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 102kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 112kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 122kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 133kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 143kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 153kB 17.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 163kB 17.1MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 174kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 184kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 194kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 204kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 215kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 225kB 17.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 235kB 17.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 245kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 256kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 266kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 276kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 286kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 296kB 17.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 307kB 17.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 317kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 327kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 337kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 348kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 358kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 368kB 17.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 378kB 17.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 389kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 399kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 409kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 419kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 430kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 440kB 17.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 450kB 17.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 460kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 471kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 481kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 491kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 501kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 512kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 522kB 17.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 532kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 542kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 552kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 563kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 573kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 583kB 17.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 706kB 54.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 49.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 57.1MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest_asyncio in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gesRSfL4AmOX"
      },
      "source": [
        "import tensorflow as tf\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "else:\n",
        "    print(\"No GPU found, model running on CPU\")\n",
        "import tensorflow_federated as tff\n",
        "#from chexpert_parser import load_dataset, feature_description\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import IPython.display as display\n",
        "import collections\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.random.set_seed(123456789)\n",
        "np.random.seed(123456789)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZHrc_nuPhjz"
      },
      "source": [
        "# Classi per le custom metrics\n",
        "\n",
        "class LabelAUC_alt(tf.keras.metrics.AUC):\n",
        "    def __init__(self, label_id, name='label_auc_alt', **kwargs):\n",
        "        super(LabelAUC_alt, self).__init__(name=name, **kwargs)\n",
        "        self.label_id = label_id\n",
        "        self.auc = tf.constant(0)\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.auc = super(LabelAUC_alt, self).update_state(y_true[:, self.label_id], y_pred[:, self.label_id])\n",
        "\n",
        "    def result(self):\n",
        "        return print(self.auc)\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.auc.assign(0)\n",
        "\n",
        "class LabelAUC(tf.keras.metrics.AUC):\n",
        "    def __init__(self, label_id, name=\"label_auc\", **kwargs):\n",
        "        super(LabelAUC, self).__init__(name=name, **kwargs)\n",
        "        self.label_id = label_id\n",
        " \n",
        "    def update_state(self, y_true, y_pred, **kwargs):\n",
        "        return super(LabelAUC, self).update_state(y_true[:, self.label_id], y_pred[:, self.label_id], **kwargs)\n",
        " \n",
        "    def result(self):\n",
        "        return super(LabelAUC, self).result()\n",
        "    \n",
        " \n",
        "class MeanAUC_alt(tf.keras.metrics.AUC): # mean\n",
        "    def __init__(self, name=\"label_mean_auc\", **kwargs):\n",
        "        super(MeanAUC, self).__init__(name=name, **kwargs)\n",
        "        self.aucs = [LabelAUC(label_id=2), LabelAUC(label_id=5), LabelAUC(label_id=6), LabelAUC(label_id=8), LabelAUC(label_id=10)]\n",
        "\n",
        "    def update_state(self, y_true, y_pred, **kwargs):\n",
        "        self.mean=tf.constant(0)\n",
        "        for auc in self.aucs:\n",
        "            auc.update_state(y_true, y_pred)\n",
        "        self.mean=(tf.constant(tf.reduce_mean([self.aucs[0].result(), self.aucs[1].result(), self.aucs[2].result(), self.aucs[3].result(), self.aucs[4].result()])))\n",
        "\n",
        "    def result(self):\n",
        "        return self.mean\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.mean=tf.constant(0)\n",
        "\n",
        "class MeanAUC(LabelAUC): \n",
        "    def __init__(self, label_id, name=\"label_mean_auc\", **kwargs):\n",
        "        super(MeanAUC, self).__init__(label_id=label_id, name=name, **kwargs)\n",
        "        self.aucs = [LabelAUC(label_id=label_id[0]), LabelAUC(label_id=label_id[1]), LabelAUC(label_id=label_id[2]), LabelAUC(label_id=label_id[3]), LabelAUC(label_id=label_id[4])]\n",
        "\n",
        "    def update_state(self, y_true, y_pred, **kwargs):\n",
        "        for auc in self.aucs:\n",
        "            auc.update_state(y_true, y_pred)\n",
        "    \n",
        "    def result(self):\n",
        "        return tf.reduce_mean([auc.result().numpy() for auc in self.aucs])\n",
        "\n",
        "    def reset_states(self):\n",
        "        return super(LabelAUC, self).reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP8CImkTCteU"
      },
      "source": [
        "# Funzioni per il parsing dei tfrecords\n",
        "\n",
        "def record_parser(example):\n",
        "\texample_fmt = {\n",
        "\t\t'label': tf.io.FixedLenFeature([14], tf.float32),\n",
        "\t\t'image': tf.io.FixedLenFeature([],tf.string, default_value='')}\n",
        "\tparsed = tf.io.parse_single_example(example, example_fmt)\n",
        "\timage = tf.image.resize_with_crop_or_pad(tf.io.decode_png(parsed[\"image\"],channels=3), 224, 224)\n",
        "\timage = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\treturn image, parsed['label']\n",
        "\n",
        "def normalize_image(img,labels):\n",
        "\timagenet_mean = np.array([0.485, 0.456, 0.406])\n",
        "\timagenet_std = np.array([0.229, 0.224, 0.225])\n",
        "\timg = (img - imagenet_mean) / imagenet_std\n",
        "\treturn img,labels\n",
        "\n",
        "def make_dataset(filename):\n",
        "\tdataset = tf.data.TFRecordDataset(filename)\n",
        "\tparsed_dataset = dataset.map(record_parser,num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
        "\tparsed_dataset = parsed_dataset.map(normalize_image,num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
        "\treturn parsed_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydRHwGzHUSIy"
      },
      "source": [
        "# Load Datasets\n",
        "\n",
        "TAKE_ONLY = None\n",
        "dataset_paths = {\n",
        "  'client_0': '/content/drive/MyDrive/tfrecords/nolat/Unbalanced/client0_norm.tfrecords',\n",
        "  'client_1': '/content/drive/MyDrive/tfrecords/nolat/Unbalanced/client1_norm.tfrecords',\n",
        "  'client_2': '/content/drive/MyDrive/tfrecords/nolat/Unbalanced/client2_norm.tfrecords',\n",
        "  'client_3': '/content/drive/MyDrive/tfrecords/nolat/Unbalanced/client3_norm.tfrecords',\n",
        "  'client_4': '/content/drive/MyDrive/tfrecords/nolat/Unbalanced/client4_norm.tfrecords',\n",
        "}\n",
        "client_list = sorted(dataset_paths.keys())\n",
        "client_datasets = {client: make_dataset(dataset_paths[client]).batch(32, drop_remainder=False).prefetch(1) for client in client_list}\n",
        "\n",
        "val_path = '/content/drive/MyDrive/tfrecords/nolat/Unbalanced/valid_norm.tfrecords'\n",
        "val_dataset = make_dataset(val_path).batch(32, drop_remainder=False).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vaf2G0RAPMiZ"
      },
      "source": [
        "### Create Federated Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LogWp5oOY31"
      },
      "source": [
        "# Create the ClientData abstraction for the federated dataset\n",
        "chex_train = tff.simulation.ClientData.from_clients_and_fn(client_list, lambda client: client_datasets[client])\n",
        "\n",
        "# Fetch the dataset for each client\n",
        "federated_train_data = [chex_train.create_tf_dataset_for_client(client) for client in client_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w11IrRN3nqoy"
      },
      "source": [
        "# Funzioni per train e validation step\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, x, y):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        output = model(x, training=True)\n",
        "        loss_value = loss_fn(y, output)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    del tape\n",
        "    compute_metrics(y, output, run='training')\n",
        "    return loss_value\n",
        "\n",
        "@tf.function\n",
        "def validation_step(model, x, y):\n",
        "    output = model(x, training=False)\n",
        "    loss = loss_fn(y, output)\n",
        "    compute_metrics(y, output, run='validation')\n",
        "    return loss, output\n",
        "\n",
        "def compute_metrics(y_true, y_pred, run):\n",
        "    if run == 'training':\n",
        "        auc_train.update_state(y_true, y_pred)\n",
        "        mean_auc_train.update_state(y_true, y_pred)\n",
        "        auc_train_card.update_state(y_true, y_pred)\n",
        "        auc_train_edema.update_state(y_true, y_pred)\n",
        "        auc_train_cons.update_state(y_true, y_pred)\n",
        "        auc_train_atel.update_state(y_true, y_pred)\n",
        "        auc_train_peff.update_state(y_true, y_pred)\n",
        "    if run == 'validation':\n",
        "        auc_valid.update_state(y_true, y_pred)\n",
        "        mean_auc_valid.update_state(y_true, y_pred)\n",
        "        auc_valid_card.update_state(y_true, y_pred)\n",
        "        auc_valid_edema.update_state(y_true, y_pred)\n",
        "        auc_valid_cons.update_state(y_true, y_pred)\n",
        "        auc_valid_atel.update_state(y_true, y_pred)\n",
        "        auc_valid_peff.update_state(y_true, y_pred)\n",
        "\n",
        "def callback_earlyStopping(MetricList, min_delta=0.1, patience=20, mode='min'):\n",
        "    #No early stopping for the first patience epochs \n",
        "    if len(MetricList) <= patience:\n",
        "        return False\n",
        "    \n",
        "    min_delta = abs(min_delta)\n",
        "    if mode == 'min':\n",
        "      min_delta *= -1\n",
        "    else:\n",
        "      min_delta *= 1\n",
        "    \n",
        "    #last patience epochs \n",
        "    last_patience_epochs = [x + min_delta for x in MetricList[::-1][1:patience + 1]]\n",
        "    current_metric = MetricList[::-1][0]\n",
        "    \n",
        "    if mode == 'min':\n",
        "        if current_metric >= max(last_patience_epochs):\n",
        "            print(f'Metric did not decrease for the last {patience} epochs.')\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    else:\n",
        "        if current_metric <= min(last_patience_epochs):\n",
        "            print(f'Metric did not increase for the last {patience} epochs.')\n",
        "            return True\n",
        "        else:\n",
        "            return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w85CCnKQZeat"
      },
      "source": [
        "### Create Federated Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsWnaW4v_vRE"
      },
      "source": [
        "from tensorflow.keras.applications.densenet import DenseNet201,DenseNet121,DenseNet169\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.nasnet import NASNetMobile\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Activation, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "import functools\n",
        "\n",
        "\n",
        "def create_mobilenet():\n",
        "    base_model = MobileNet(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    predictions = Dense(14, activation='sigmoid')(x)\n",
        "    model = Model(inputs=base_model.inputs, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "def model_fn():\n",
        "    input_spec_test = ( \n",
        "        tf.TensorSpec(shape=[None, 224, 224, 3], dtype=tf.float32), \n",
        "        tf.TensorSpec(shape=[None, 14], dtype=tf.float32) \n",
        "    )\n",
        "    # We _must_ create a new model here, and _not_ capture it from an external\n",
        "    # scope. TFF will call this within different graph contexts.\n",
        "    #model = load_model('/content/drive/MyDrive/Modelli_Tesi/NOLAT/Federated/C/model_4.h5', compile=None)\n",
        "    model = create_mobilenet()\n",
        "    keras_model = tf.keras.models.clone_model(model)\n",
        "    return tff.learning.from_keras_model(\n",
        "        keras_model,\n",
        "        input_spec = input_spec_test,\n",
        "        #input_spec = preprocessed_dataset.element_spec,\n",
        "        #input_spec = (keras_model.input.shape, keras_model.output.shape),\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFHJzSIm_vHL"
      },
      "source": [
        "# Creo il federated_process\n",
        "\n",
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.4),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.9))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "PQnDU6gqT2NS",
        "outputId": "9333bc6f-0f8a-47f3-c57f-4756962e3610"
      },
      "source": [
        "# Verifico signature del processo\n",
        "\n",
        "str(iterative_process.initialize.type_signature)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'( -> <model=<trainable=<float32[3,3,3,32],float32[32],float32[32],float32[3,3,32,1],float32[32],float32[32],float32[1,1,32,64],float32[64],float32[64],float32[3,3,64,1],float32[64],float32[64],float32[1,1,64,128],float32[128],float32[128],float32[3,3,128,1],float32[128],float32[128],float32[1,1,128,128],float32[128],float32[128],float32[3,3,128,1],float32[128],float32[128],float32[1,1,128,256],float32[256],float32[256],float32[3,3,256,1],float32[256],float32[256],float32[1,1,256,256],float32[256],float32[256],float32[3,3,256,1],float32[256],float32[256],float32[1,1,256,512],float32[512],float32[512],float32[3,3,512,1],float32[512],float32[512],float32[1,1,512,512],float32[512],float32[512],float32[3,3,512,1],float32[512],float32[512],float32[1,1,512,512],float32[512],float32[512],float32[3,3,512,1],float32[512],float32[512],float32[1,1,512,512],float32[512],float32[512],float32[3,3,512,1],float32[512],float32[512],float32[1,1,512,512],float32[512],float32[512],float32[3,3,512,1],float32[512],float32[512],float32[1,1,512,512],float32[512],float32[512],float32[3,3,512,1],float32[512],float32[512],float32[1,1,512,1024],float32[1024],float32[1024],float32[3,3,1024,1],float32[1024],float32[1024],float32[1,1,1024,1024],float32[1024],float32[1024],float32[1024,14],float32[14]>,non_trainable=<float32[32],float32[32],float32[32],float32[32],float32[64],float32[64],float32[64],float32[64],float32[128],float32[128],float32[128],float32[128],float32[128],float32[128],float32[128],float32[128],float32[256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[256],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[512],float32[1024],float32[1024],float32[1024],float32[1024],float32[1024],float32[1024]>>,optimizer_state=<int64>,delta_aggregate_state=<value_sum_process=<>,weight_sum_process=<>>,model_broadcast_state=<>>@SERVER)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byjp4dNgT4o3",
        "outputId": "ead1c83e-44a7-499d-aa72-e99fe796c493"
      },
      "source": [
        "# Inizializzo lo stato del federated_prcess.\n",
        "'''\n",
        "N.B. Questo deve restituire Instructions for updating:\n",
        "    Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
        "\n",
        "    WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:59: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
        "    Instructions for updating:\n",
        "    Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
        "\n",
        "Se questo non viene restituito lo stato non è inizializzato correttamente, bisogna quindi ricreare l'iterative_process\n",
        "'''\n",
        "\n",
        "state = iterative_process.initialize()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:59: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:59: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYvZp1FSQHUo"
      },
      "source": [
        "### Federated Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahuMYvjpn4CQ"
      },
      "source": [
        "auc_valid = tf.keras.metrics.AUC(name='auc_valid')\n",
        "mean_auc_valid = MeanAUC(label_id=[2,5,6,8,10], name='mean_auc_valid')\n",
        "auc_valid_card = LabelAUC(2, name='auc_valid_card')\n",
        "auc_valid_edema = LabelAUC(5, name='auc_valid_edema')\n",
        "auc_valid_cons = LabelAUC(6, name='auc_valid_cons')\n",
        "auc_valid_atel = LabelAUC(8, name='auc_valid_atel')\n",
        "auc_valid_peff = LabelAUC(10, name='auc_valid_peff')\n",
        "\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "optimizer = tf.keras.optimizers.SGD(1e-3)\n",
        "\n",
        "outputFolder = \"/content/drive/MyDrive/Modelli_Tesi/NOLAT/Federated/Unbalanced_Coarse_A\"\n",
        "if not os.path.exists(outputFolder):\n",
        "    os.makedirs(outputFolder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lZUArLpkrZ_"
      },
      "source": [
        "#Inizializzo pesi poichè sto utilizzando una pretrained mobilenet. \n",
        "#Questo deve essere fatto solo se si utilizzano modelli pretrained\n",
        "\n",
        "keras_model = create_mobilenet()\n",
        "keras_model.compile(loss=tf.keras.losses.BinaryCrossentropy(), metrics=[LabelAUC(2, name='label_auc_2')])\n",
        "\n",
        "state = tff.learning.state_with_new_model_weights(\n",
        "    state,\n",
        "    trainable_weights=[v.numpy() for v in keras_model.trainable_weights],\n",
        "    non_trainable_weights=[\n",
        "        v.numpy() for v in keras_model.non_trainable_weights\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJVk6oauN3Ky",
        "outputId": "583766e9-1557-4169-8700-d1b769b8b916"
      },
      "source": [
        "NUM_ROUNDS = 5\n",
        "for round_num in range(NUM_ROUNDS):\n",
        "    #TRAINING\n",
        "    state, metrics = iterative_process.next(state, federated_train_data)\n",
        "    print('round {:2d}, metrics={}'.format(round_num, metrics))\n",
        "\n",
        "    # Dopo ogni round di training estraggo i pesi del modello globale che assegno poi ad un nuovo modello per il calcolo delle metrics.\n",
        "    # Unico modo attualmente per validare il modello\n",
        "    keras_model = create_mobilenet()\n",
        "    keras_model.compile(loss=tf.keras.losses.BinaryCrossentropy(), metrics=[LabelAUC(2, name='label_auc_2')])\n",
        "    state.model.assign_weights_to(keras_model)\n",
        "\n",
        "\n",
        "    # VALIDATION\n",
        "    for step, row in enumerate(val_dataset):\n",
        "        val_loss = validation_step(keras_model, row[0], row[1])\n",
        "        if step % 100 == 0:\n",
        "            template = 'VALIDATION: Round {}, Step {}, AUC MEAN: {}, AUC_cardiomegaly: {}, AUC_edema: {}, AUC_consolidation: {}, AUC_atelectasis: {}, AUC_pleural_effusion: {}, AUC_keras: {}'\n",
        "            print(template.format(round_num, step, mean_auc_valid.result().numpy(), auc_valid_card.result().numpy(), auc_valid_edema.result().numpy(), auc_valid_cons.result().numpy(), auc_valid_atel.result().numpy(), auc_valid_peff.result().numpy(), auc_valid.result().numpy()))\n",
        "\n",
        "    keras_model.save(outputFolder+'/model_'+str(round_num)+'.h5')\n",
        "    keras_model.save_weights(outputFolder+'/weights_'+str(round_num)+'.h5')\n",
        "\n",
        "    e = {'Round': [round_num], 'AUC': [auc_valid.result().numpy()], 'AUC Mean': [mean_auc_valid.result().numpy()], 'AUC_cardiomegaly': [auc_valid_card.result().numpy()], 'AUC_edema': [auc_valid_edema.result().numpy()], 'AUC_consolidation': [auc_valid_cons.result().numpy()], 'AUC_atelectasis': [auc_valid_atel.result().numpy()], 'AUC_pleural_effusion': [auc_valid_peff.result().numpy()]}\n",
        "    log_e = pd.DataFrame(data=e)\n",
        "    if round_num == 0:\n",
        "        log_tot = log_e\n",
        "    else:\n",
        "        log_tot = log_tot.append(log_e)\n",
        "\n",
        "    print(log_tot)\n",
        "\n",
        "    auc_valid.reset_states()\n",
        "    mean_auc_valid.reset_states()\n",
        "    auc_valid_card.reset_states()\n",
        "    auc_valid_edema.reset_states()\n",
        "    auc_valid_cons.reset_states()\n",
        "    auc_valid_atel.reset_states()\n",
        "    auc_valid_peff.reset_states()\n",
        "\n",
        "log_tot.to_csv(outputFolder+'/log.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "round  0, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('binary_accuracy', 0.847308), ('loss', 0.33145422)])), ('stat', OrderedDict([('num_examples', 178135)]))])\n",
            "VALIDATION: Round 0, Step 0, AUC MEAN: 0.5924478769302368, AUC_cardiomegaly: 0.5, AUC_edema: 0.7005208134651184, AUC_consolidation: 0.5, AUC_atelectasis: 0.5, AUC_pleural_effusion: 0.76171875, AUC_keras: 0.6855430006980896\n",
            "VALIDATION: Round 0, Step 100, AUC MEAN: 0.5805825591087341, AUC_cardiomegaly: 0.5, AUC_edema: 0.6324754953384399, AUC_consolidation: 0.5, AUC_atelectasis: 0.5013314485549927, AUC_pleural_effusion: 0.7691059708595276, AUC_keras: 0.6490873694419861\n",
            "VALIDATION: Round 0, Step 200, AUC MEAN: 0.5820562243461609, AUC_cardiomegaly: 0.5, AUC_edema: 0.6299571990966797, AUC_consolidation: 0.5, AUC_atelectasis: 0.500613808631897, AUC_pleural_effusion: 0.7797102332115173, AUC_keras: 0.6454182863235474\n",
            "VALIDATION: Round 0, Step 300, AUC MEAN: 0.5828206539154053, AUC_cardiomegaly: 0.5, AUC_edema: 0.6358977556228638, AUC_consolidation: 0.5, AUC_atelectasis: 0.5003806352615356, AUC_pleural_effusion: 0.7778248190879822, AUC_keras: 0.6439595222473145\n",
            "VALIDATION: Round 0, Step 400, AUC MEAN: 0.5826431512832642, AUC_cardiomegaly: 0.5, AUC_edema: 0.6340267062187195, AUC_consolidation: 0.5, AUC_atelectasis: 0.5001953840255737, AUC_pleural_effusion: 0.7789938449859619, AUC_keras: 0.6443442702293396\n",
            "   Round       AUC  ...  AUC_atelectasis  AUC_pleural_effusion\n",
            "0      0  0.644392  ...         0.500195              0.779159\n",
            "\n",
            "[1 rows x 8 columns]\n",
            "round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('binary_accuracy', 0.85353523), ('loss', 0.31708276)])), ('stat', OrderedDict([('num_examples', 178135)]))])\n",
            "VALIDATION: Round 1, Step 0, AUC MEAN: 0.6204427480697632, AUC_cardiomegaly: 0.5, AUC_edema: 0.8229166865348816, AUC_consolidation: 0.5, AUC_atelectasis: 0.5, AUC_pleural_effusion: 0.779296875, AUC_keras: 0.7313920855522156\n",
            "VALIDATION: Round 1, Step 100, AUC MEAN: 0.6182008981704712, AUC_cardiomegaly: 0.5, AUC_edema: 0.7887541651725769, AUC_consolidation: 0.5, AUC_atelectasis: 0.5067049860954285, AUC_pleural_effusion: 0.795545220375061, AUC_keras: 0.7069436311721802\n",
            "VALIDATION: Round 1, Step 200, AUC MEAN: 0.6208375692367554, AUC_cardiomegaly: 0.5, AUC_edema: 0.7910434007644653, AUC_consolidation: 0.5, AUC_atelectasis: 0.5069069266319275, AUC_pleural_effusion: 0.806237518787384, AUC_keras: 0.7040843963623047\n",
            "VALIDATION: Round 1, Step 300, AUC MEAN: 0.6209398508071899, AUC_cardiomegaly: 0.5, AUC_edema: 0.7936199307441711, AUC_consolidation: 0.5, AUC_atelectasis: 0.5073246359825134, AUC_pleural_effusion: 0.8037548661231995, AUC_keras: 0.7029036283493042\n",
            "VALIDATION: Round 1, Step 400, AUC MEAN: 0.6205103993415833, AUC_cardiomegaly: 0.5, AUC_edema: 0.7894974946975708, AUC_consolidation: 0.5, AUC_atelectasis: 0.5073397159576416, AUC_pleural_effusion: 0.8057147264480591, AUC_keras: 0.7032947540283203\n",
            "   Round       AUC  ...  AUC_atelectasis  AUC_pleural_effusion\n",
            "0      0  0.644392  ...         0.500195              0.779159\n",
            "0      1  0.703349  ...         0.507306              0.805881\n",
            "\n",
            "[2 rows x 8 columns]\n",
            "round  2, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('binary_accuracy', 0.8570017), ('loss', 0.30987972)])), ('stat', OrderedDict([('num_examples', 178135)]))])\n",
            "VALIDATION: Round 2, Step 0, AUC MEAN: 0.6158344745635986, AUC_cardiomegaly: 0.5, AUC_edema: 0.8177083730697632, AUC_consolidation: 0.5, AUC_atelectasis: 0.47826087474823, AUC_pleural_effusion: 0.783203125, AUC_keras: 0.7219855785369873\n",
            "VALIDATION: Round 2, Step 100, AUC MEAN: 0.6237843036651611, AUC_cardiomegaly: 0.5, AUC_edema: 0.791205883026123, AUC_consolidation: 0.5, AUC_atelectasis: 0.5339239835739136, AUC_pleural_effusion: 0.7937914729118347, AUC_keras: 0.6979809999465942\n",
            "VALIDATION: Round 2, Step 200, AUC MEAN: 0.627081573009491, AUC_cardiomegaly: 0.5, AUC_edema: 0.7951507568359375, AUC_consolidation: 0.5, AUC_atelectasis: 0.5378638505935669, AUC_pleural_effusion: 0.8023933172225952, AUC_keras: 0.6953678131103516\n",
            "VALIDATION: Round 2, Step 300, AUC MEAN: 0.6270670890808105, AUC_cardiomegaly: 0.5, AUC_edema: 0.7962016463279724, AUC_consolidation: 0.5, AUC_atelectasis: 0.5410367846488953, AUC_pleural_effusion: 0.7980968952178955, AUC_keras: 0.6944043040275574\n",
            "VALIDATION: Round 2, Step 400, AUC MEAN: 0.6263286471366882, AUC_cardiomegaly: 0.5, AUC_edema: 0.7919939756393433, AUC_consolidation: 0.5, AUC_atelectasis: 0.5405796766281128, AUC_pleural_effusion: 0.7990696430206299, AUC_keras: 0.6944624781608582\n",
            "   Round       AUC  ...  AUC_atelectasis  AUC_pleural_effusion\n",
            "0      0  0.644392  ...         0.500195              0.779159\n",
            "0      1  0.703349  ...         0.507306              0.805881\n",
            "0      2  0.694507  ...         0.540484              0.799224\n",
            "\n",
            "[3 rows x 8 columns]\n",
            "round  3, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('binary_accuracy', 0.8589796), ('loss', 0.30524814)])), ('stat', OrderedDict([('num_examples', 178135)]))])\n",
            "VALIDATION: Round 3, Step 0, AUC MEAN: 0.616355299949646, AUC_cardiomegaly: 0.5, AUC_edema: 0.8281249403953552, AUC_consolidation: 0.5, AUC_atelectasis: 0.47826087474823, AUC_pleural_effusion: 0.775390625, AUC_keras: 0.7196654677391052\n",
            "VALIDATION: Round 3, Step 100, AUC MEAN: 0.6197435259819031, AUC_cardiomegaly: 0.5, AUC_edema: 0.7915433645248413, AUC_consolidation: 0.5, AUC_atelectasis: 0.5370178818702698, AUC_pleural_effusion: 0.7701565027236938, AUC_keras: 0.6940736174583435\n",
            "VALIDATION: Round 3, Step 200, AUC MEAN: 0.6226885914802551, AUC_cardiomegaly: 0.5, AUC_edema: 0.7941629886627197, AUC_consolidation: 0.5, AUC_atelectasis: 0.5403006076812744, AUC_pleural_effusion: 0.7789793014526367, AUC_keras: 0.6913103461265564\n",
            "VALIDATION: Round 3, Step 300, AUC MEAN: 0.6230180859565735, AUC_cardiomegaly: 0.5, AUC_edema: 0.794183075428009, AUC_consolidation: 0.5, AUC_atelectasis: 0.5435417294502258, AUC_pleural_effusion: 0.7773657441139221, AUC_keras: 0.6907013654708862\n",
            "VALIDATION: Round 3, Step 400, AUC MEAN: 0.6222251653671265, AUC_cardiomegaly: 0.5, AUC_edema: 0.7907238602638245, AUC_consolidation: 0.5, AUC_atelectasis: 0.5424922704696655, AUC_pleural_effusion: 0.7779096961021423, AUC_keras: 0.690778374671936\n",
            "   Round       AUC  ...  AUC_atelectasis  AUC_pleural_effusion\n",
            "0      0  0.644392  ...         0.500195              0.779159\n",
            "0      1  0.703349  ...         0.507306              0.805881\n",
            "0      2  0.694507  ...         0.540484              0.799224\n",
            "0      3  0.690820  ...         0.542337              0.777948\n",
            "\n",
            "[4 rows x 8 columns]\n",
            "round  4, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('binary_accuracy', 0.8605255), ('loss', 0.3013032)])), ('stat', OrderedDict([('num_examples', 178135)]))])\n",
            "VALIDATION: Round 4, Step 0, AUC MEAN: 0.6212447285652161, AUC_cardiomegaly: 0.5, AUC_edema: 0.8307291269302368, AUC_consolidation: 0.5, AUC_atelectasis: 0.49033820629119873, AUC_pleural_effusion: 0.78515625, AUC_keras: 0.7247159481048584\n",
            "VALIDATION: Round 4, Step 100, AUC MEAN: 0.6224684119224548, AUC_cardiomegaly: 0.5, AUC_edema: 0.7913415431976318, AUC_consolidation: 0.5, AUC_atelectasis: 0.5662981867790222, AUC_pleural_effusion: 0.7547023296356201, AUC_keras: 0.6972971558570862\n",
            "VALIDATION: Round 4, Step 200, AUC MEAN: 0.6254092454910278, AUC_cardiomegaly: 0.5, AUC_edema: 0.7923986911773682, AUC_consolidation: 0.5, AUC_atelectasis: 0.5694975256919861, AUC_pleural_effusion: 0.7651499509811401, AUC_keras: 0.6949750185012817\n",
            "VALIDATION: Round 4, Step 300, AUC MEAN: 0.6249469518661499, AUC_cardiomegaly: 0.5, AUC_edema: 0.790728747844696, AUC_consolidation: 0.5, AUC_atelectasis: 0.571831226348877, AUC_pleural_effusion: 0.7621746063232422, AUC_keras: 0.6941978335380554\n",
            "VALIDATION: Round 4, Step 400, AUC MEAN: 0.6238584518432617, AUC_cardiomegaly: 0.5, AUC_edema: 0.7864326238632202, AUC_consolidation: 0.5, AUC_atelectasis: 0.5701460242271423, AUC_pleural_effusion: 0.7627134323120117, AUC_keras: 0.6940521597862244\n",
            "   Round       AUC  ...  AUC_atelectasis  AUC_pleural_effusion\n",
            "0      0  0.644392  ...         0.500195              0.779159\n",
            "0      1  0.703349  ...         0.507306              0.805881\n",
            "0      2  0.694507  ...         0.540484              0.799224\n",
            "0      3  0.690820  ...         0.542337              0.777948\n",
            "0      4  0.694066  ...         0.569593              0.762758\n",
            "\n",
            "[5 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}